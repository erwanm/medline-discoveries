---
title: "Mining Impactful Discoveries 2: Analysis"
author: "Erwan Moreau"
date: "November 2021"
output:
 html_document:
    fig_width: 10
    fig_height: 4
---


```{r setup, include=FALSE}
library(knitr)
library(rmarkdown)
knitr::opts_chunk$set(echo = TRUE)
```


# medline-discoveries: analysis

## Overview

This document is part of the documentation for the [Medline Discoveries repository](https://github.com/erwanm/medline-discoveries), which is the companion code for the paper "Mining impactful discoveries from the biomedical literature" **TODO link**.

- [The main documentation](https://erwanm.github.io/medline-discoveries/1-detecting-surges.html) describes how to generate the output data (i.e. detecting surges) using the provided R implementation.
- This part of the documentation covers additional analysis of the results, including how the graphs and tables presented in the paper are obtained.

### Rmd Options

This document was generated from an [R Markdown](https://rmarkdown.rstudio.com/) source file. The source file is provided in the repository, allowing full reproducibility of the experiments presented in the paper. It can be executed through the RStudio interface ("knit" button) or as follows:

```
rmarkdown::render('2-analysis.Rmd')
```

The `.Rmd` source document can be configured by modifying the following lines:

```{r myoptions}
# directory for the input data (Medline frequency data)
dataPathInput <- 'data/input'
dataPathInputStatic <- paste(dataPathInput,'static',sep='/')
# directory for the output data (extracted surges from the main process in step 1)
dataPathOutput <- 'data/output'

# by default using the Medline ND subset:
# the static suffix is different from the dynamic one for some reason (sorry for that)
data.suffix <- '.min100.ND'
# uncomment the following line in order to use the full Medline data instead (not tested with this Rmd!):
# data.suffix <- '.min100'

# set to TRUE for quick execution with a random subset of the data
shortVersion <- FALSE
# set to TRUE in order to save the graphs used in the paper
savePaperGraphs <- TRUE
```

Notes:

- If the option `shortVersion` is set to `FALSE`, the process requires at least 16GB RAM. 
- Note: the option to use the full Medline data (`data.suffix <- '.min100'`) has not been tested with this Rmd document.

```{r initialization}
source('discoveries.R')
```

## Requirements

The software requirements are the same as for [the first part](1-detecting-surges.html#software)

This part requires the same input data as in [the first part](1-detecting-surges.html#data), but also the output generated as a result of applying the process. Both datasets can be downloaded at **TODO link**.

By default the input data is expected in the subdirectory `data/input` and the output data (unsuprisingly)  in `data/output`.

## Loading


```{r load}
dynamic_joint <- loadDynamicData(dataPathInput,suffix=data.suffix, indivOrJoint = 'joint')
dynamic_indiv <- loadDynamicData(dataPathInput,suffix=data.suffix, indivOrJoint = 'indiv')
dynamic_total <- loadDynamicTotalFile(dataPathInput)
static_data <- loadStaticData(dir=dataPathInputStatic,suffix=data.suffix)
```


## Selecting some of the specific concepts presented in the paper

```{r als}
als <- filterConcepts(dynamic_joint, 'D000690')
selectedALS <- filterConcepts(als,c('D051379','D000073885','D000870','D019782','D008875'))
parkinson <- filterConcepts(dynamic_joint, 'D010300')
caseParkinson <- filterConcepts(parkinson, 'D013378')
```

## Selecting a random subset

Note: in some of the graphs (trend distribution), the representation of all the points is very computationally heavy, causing extremely long duration even to just load the pdf file. This is why a random subset of relations is used even in the case where `shortVersion` is set to `FALSE`.

```{r, init.data.short}
if (shortVersion) {
  dynamic_joint<-pickRandomDynamic(dynamic_joint,n=1000)
  dynamic_joint.rndsubset<-dynamic_joint
} else {
  dynamic_joint.rndsubset<-pickRandomDynamic(dynamic_joint,n=20000)
}
```

In order to avoid cases with insufficient data, it is possible to filter out rows with less than some minimum frequency $m$ (the relation must have at least one year with a frequency higher than $m$). It is also possible to specify the number of cases to pick:

```{r rnd2}
three_relations<-pickRandomDynamic(dynamic_joint,n=3, minFreqYear = 200)
```


## Displaying relations frequency across time with their concepts names

Using the relations selected randomly above:


```{r display2}
displaySeveralPairsData(three_relations,static_data,dynamic_total)
```

## Displaying the ALS cases


```{r expl1}
g<-displaySeveralPairsData(selectedALS,static_data,dynamic_total,excludeConceptsFromName = 'D000690',ncol=5)
g
```

```{r expl1.save, echo=savePaperGraphs, eval=savePaperGraphs}
ggsave('expl1.pdf',g)
```

## Displaying measures

```{r measures1}
g <- displayMultiMeasure(selectedALS,dynamic_indiv,dynamic_total,static_data,windows=c(1,3,5),measures=c('prob.joint','pmi','npmi','mi','nmi','scp'),excludeConceptsFromName = 'D000690')
g
```


```{r measures1.save, echo=savePaperGraphs, eval=savePaperGraphs}
ggsave('expl-measures.pdf',g+ theme(text=element_text(size=14),legend.position="none",axis.title.x=element_blank(),axis.title.y=element_blank()),width=20,height=16,units = "cm")
```

## Study of the trend parameters

### Using simple frequency, indicator 'rate'

```{r trend1}
displayMultiTrend(selectedALS,dynamic_indiv,dynamic_total,static_data,indicator='rate',measure = 'prob.joint',excludeConceptsFromName = 'D000690')
```

### Using NMI, indicator 'rate'

```{r trend2}
displayMultiTrend(selectedALS,dynamic_indiv,dynamic_total,static_data,indicator='rate',measure = 'nmi',excludeConceptsFromName = 'D000690')
```

### Using NMI, indicator 'diff'

```{r trend3}
displayMultiTrend(selectedALS,dynamic_indiv,dynamic_total,static_data,indicator='diff',measure = 'nmi',excludeConceptsFromName = 'D000690')
```


## Examples for indicators and surges

This graph shows the surge year(s) in the plot of the probability across years (this is not very useful actually).

### Using simple frequency

```{r surges1}
g <- displaySurges(caseParkinson,dynamic_indiv,dynamic_total,static_data,windows=c(1,3), indicators=c('rate','diff'),withTitle = TRUE)
g
```

### Using NMI

```{r surges2}
g <- displaySurges(caseParkinson,dynamic_indiv,dynamic_total,static_data,valueCol='nmi',windows=c(1,3,5), indicators=c('rate','diff'),withTitle = TRUE)
g
# saving the graph as pdf:
# ggsave('expl1.pdf',g)
```

## Displaying the trend distribution




### 'Standard' version


```{r sample.ma}
relations.ma <- computeMovingAverage(dynamic_joint.rndsubset,dynamic_total, window=5)
indiv.ma <- computeMovingAverage(dynamic_indiv,dynamic_total, window=5)
```

The following graphs show different versions of the histogram of the `trend` values: with/without logarithmic scale on the X and/or Y axis.

The vertical lines show the outlier threshold calculated as $Q_3+k \times IQR$, where $k$ is either 1.5 or 3 ("far outliers").

```{r trend.distrib1}
l<-displayTrendDistribution1(relations.ma,indiv.ma)
l$x0.y0
l$x0.y1
l$x1.y0
l$x1.y1
```

### Quantile plot ("flat" distribution)

These graphs show the "flat" distribution (probably not a standard name): 

- The points are sorted by `trend` and their relative rank (rank divided by number of points) is plotted as X. In other words, the X axis represents all the quantile positions with respect to `trend`.
- The `trend` value shown on the Y axis is normalized between [0,1] for every measure.

Note that the random selection can affect the graph significantly since the extreme points are rare. 

```{r trend.distrib3}
#displayTrendDistribution2(relations.ma,indiv.ma,withRect = FALSE)
g<-displayTwoPlotsDistribTrend(relations.ma,indiv.ma)
g
```

Note: the `pdf` format makes the  graph take a very long time to load, this is why `png` is recommended for this graph.

```{r trend.distrib3.save, echo=savePaperGraphs, eval=savePaperGraphs}
ggsave('expl-trend-distrib.pdf',g,width=20,height=8,units = "cm")
ggsave('expl-trend-distrib.png',g,width=20,height=8,units = "cm")
```


## Evaluation 

## Gold standard data

Below the gold-standard dataset presented in the paper is loaded and displayed:

```{r gold}
gold <- loadGoldDiscoveries(dir='data',file='ND-discoveries-year.tsv')
kable(gold)
```


## Parameters


```{r eval}
if (shortVersion) {
  my.measures <- c('prob.joint','pmi','nmi','scp')
  my.ma <- c(1,5)
  my.indicators <- 'diff'
} else {
  my.measures <- c('prob.joint','pmi','npmi','mi','nmi','scp')
  my.ma <- c(1,3,5)
  my.indicators <- c('diff',"rate")
}
data.eval <- collectEvalDataSurgesAgainstGold(gold, dir=dataPathOutput,suffix=data.suffix,evalAt=NA,ma_windows=my.ma,measures=my.measures,indicators = my.indicators)
```


```{r eval.res}
res.eval<-evalSurgessAgainstGold(data.eval,eval_windows = c(1,3,5))
```


### Top individual configurations

```{r eval.params.indiv}
eval3 <- res.eval[eval.window==3 & mode=='first.year',]
kable(head(eval3[order(-perf),],12))
```

### Comparison by parameter


```{r eval.params.plot}
g<-displayAvgPerfByParam(res.eval,evalWindow = 3)
g
```

```{r, echo=savePaperGraphs, eval=savePaperGraphs}
ggsave('plot-params.pdf',g,width = 20,height=8,unit='cm')
```


### Overlap by pair of configurations

The overlap coefficient is calculated based on the number of relations in common between the two configurations, where "in common" means that the relation appears in both lists with their surge year within 5 years of each other.  

* Note: in the code below the window of years (5) can be set to NA. In this case the overlap coefficient is only based on relations in common (no year comparison).

```{r eval.overlap}
surges<-readMultipleSurgesFiles(measures=my.measures,indicator='diff',ma_windows = my.ma)
mat<-correlationMatrixMultiParam(surges, 5)
g<-heatMapCommonMatrix(mat)
g
```

```{r eval.overlap.save, echo=savePaperGraphs, eval=savePaperGraphs}
ggsave('heatmap-overlap.pdf',g,width=20,height=15,unit='cm')
```

## Distribution of surges across time

### Duration between the year of the first cooccurrence and the surge year


```{r eval.years.loading}
surges.scp <-loadSurgesData(dir=dataPathOutput,suffix = data.suffix,ma_window = 5,measure='scp',indicator = 'diff')
surges.scp[,first.surge:=(year==min(year)),by=key(surges.scp)]
```

```{r eval.years.joint}
x<-calculateDiffYears(surges.scp,dynamic_indiv,dynamic_joint)
ggplot(x,aes(duration.joint,fill=first.surge))+geom_histogram()
```

### Trend of surges by year

```{r eval.years.trend}
ggplot(surges.scp,aes(as.factor(year),trend))+geom_boxplot()+ylim(c(0,.02))+theme(axis.text.x=element_text(angle = -90, hjust = 0))
```

### First cooccurrences and surges

```{r eval.years}
doublePlotAcrossTime(dynamic_joint, surges.scp,bins=68,fontsize=16)
```

### Combination of multiple plots

Right plot: duration between the year where the latest of the two concepts appears (individual occurrence) and surge year:

```{r eval.years.threeplots}
g<-threePlotsAboutYears(surges.scp, dynamic_indiv, dynamic_joint)
g
```

```{r eval.years.save, echo=savePaperGraphs, eval=savePaperGraphs}
ggsave('surges-by-year.pdf',g,width=20,height=12,unit='cm')
```

## Relation between surges and frequency


Here we observe how the joint frequency of the relation relates to the status as surge or not. 

- The joint frequency is taken globally across all years (static data)
- The data is observed by unique relation (pair of concepts), i.e. a relation either has at least one surge or doesn't (multiple surges not taken into account).

The first graph below shows the distribution of surges by frequency, i.e. how many relations with surge have a particular frequency $x$. 

The number of surges decreases when the frequency increases, but we can see below that this an effect of the higher number of relations with low frequency.

```{r study.freq.1}
d<-surges.scp
d[,first.surge:=(year==min(year)),by=key(d)]
d<-d[first.surge==TRUE,]
x<-merge(d, static_data,suffixes=c('.dynamic','.static'))
ggplot(x,aes(freq.joint.static))+geom_histogram()+xlim(c(0,100000))+scale_y_log10(labels = scales::comma_format(accuracy=1,big.mark = ",", decimal.mark = "."))
```

The following graph shows the number of relations with a surge among all the relations. Note that the Y axis is logarithmic, this makes the proportion of surges look higher. For instance the first bin contains a few thousands surges among 100 millions relations.

On this graph it can be observed that the proportion of surges is roughly stable with respect to frequency.

```{r study.freq.2}
g1 <- surgesAmongRelationsByFreq(surges.scp,static_data)
g1
```

The following graph shows the proportion of relations with surges vs. non surges for every bin. It should be noted that by definition, this graph doesn't represent the proportion of a bin among the whole data: the first bins (low frequency) contain a lot more relations than the others, as seen above.

The X axis is cut at 10k in order to show the increase of the proportion of surges as frequency increases.

```{r study.freq.3}
g2 <- surgesAmongRelationsByFreq(surges.scp,static_data,asProportion = TRUE,freqmax = 10000,logY = FALSE)
g2
```

```{r eval.freq.save, echo=savePaperGraphs, eval=savePaperGraphs}
g<-plot_grid(g1,g2,labels=NULL,ncol=2)
ggsave('surges-by-freq.pdf',g,width=20,height=8,unit='cm')
```

## Qualitative results

Here we simply observe the top and bottom surges under various conditions, as described in the paper.

```{r qualitative.init}
surges.scp[,first.surge:=(year==min(year)),by=key(surges.scp)]
surges.scp.terms <- addRelationName(surges.scp,static_data)
```

These are the top 12 relations by trend without any filtering:

```{r qualitative.raw}
kable(head(surges.scp.terms[order(-trend),.(year,c1,c2,group.c1,group.c2,relation)],12))
```

### Filtering by semantic group

The flitering by semantic group can be done as follows. The [UMLS semantic groups](https://lhncbc.nlm.nih.gov/ii/tools/MetaMap/Docs/SemGroups_2018.txt) are used (the abbreviated name, first column). 

```{r qualitative.groups1}
filtered <- selectRelationsGroups(surges.scp.terms, groups1=c('CONC'), groups2=c('DISO','LIVB','ANAT')) 
```



By default both selected groups are 'DISO','CHEM','GENE','ANAT':

```{r qualitative.groups2}
filtered <- selectRelationsGroups(surges.scp.terms)
```

Top 12 after filtering:

```{r qualitative.groups3}
kable(head(filtered[order(-trend),.(year,c1,c2,group.c1,group.c2,relation)],12))
```

### Filtering by conditional probability

Same relations as above with their conditional probabilities:

```{r qualitative.raw.condi}
kable(head(filtered[order(-trend),.(year,c1,relation,prob.C1GivenC2,prob.C2GivenC1)],12))
```

Relations with a least one High conditional probability are often trivial, since one of the concepts almost always appears with the other one. 

The following function filters out relations which have at least one conditional probability higher than the threshold. It also has an option to keep only the first surge for any relation.

```{r qualitative.filter.condi}
filtered2<-filterCondProb(filtered,conditional.threshold = 0.6,onlyFirstSurge = TRUE)
kable(head(filtered2[order(-trend),.(year,c1,relation,trend)],12))
```

### Bottom surges

```{r qualitative.bottom}
kable(head(filtered2[order(-trend),.(year,c1,relation,trend)],12))
```

